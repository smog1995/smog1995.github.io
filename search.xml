<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>huadb_lab3</title>
      <link href="/2024/04/15/huadb-lab3/"/>
      <url>/2024/04/15/huadb-lab3/</url>
      
        <content type="html"><![CDATA[<p>万圣节问题的底层逻辑是，update操作<br>Update  id &#x3D; id+1<br>会新增插入数据，然后scan操作又把新插入的数据视作原来表中的数据，重复删除新增的数据再插入数据如此反复导致死循环。<br>update操作需要使用扫描表中符合条件的行，可以发现update执行器有子执行器，其实就是scan执行器，所以这两个操作的事务id和sql语句是相同的。只需在scan环节对元组做判断是否为相同的事务id和sql语句cid，相同则不送出该元组（火山模型，一次只返回一行）</p><p>实现mvcc，使用事务版本号（某种意义上是逻辑时间戳）。每个事务都有一个唯一的事务ID，被称为XID。注意：除了被BEGIN - COMMIT&#x2F;ROLLBACK包裹的一组语句会被当作一个事务对待外，不显示指定BEGIN - COMMIT&#x2F;ROLLBACK的单条语句也是一个事务。</p><p>本实验框架和pgsql的mvcc相似，其实现原理如下：</p><p>1）数据文件中存放同一逻辑行的多个行版本；<br>2）每个行版本的头部记录创建该版本的事务ID以及删除该行版本的事务的ID（分别称为xmin和xmax）；<br>3）系统保存了每个事务的状态（运行中，中止或提交）<br>4）根据上面的数据并运用一定的规则每个事务只会看到一个特定的行版本。<br>通过MVCC，读写事务可以分别在不同的行版本上工作，因此能够在互不冲突的情况下并发执行。</p><p>我们需要先介绍下隔离级别：<br><img src="https://img2.imgtp.com/2024/04/15/FEBXEUfj.png" alt="Alt text"><br>本实验要求实现读已提交，可重复读和可串行化。<br>在一般情况中，隔离级别能解决的问题如下表。<br>读脏（Dirty Read)会导致读取到未提交的数据，不可重复读会导致同个事务对同一行数据第二次读取得到的结果不一样（第二次查询时读到了其他事务新提交的数据），幻读（Phantom）会导致同个事务对同一个表第二次读取得到的行数不一样（如多了一行，少了一行）。<br>然后是mvcc中，快照读可见性判断的例子（前四个测试案例文件只需实现快照读）：<br>假设当前正执行的事务版本号为xid，要判断一个元组是否可见：<br>1.插入该元组的事务（也就是版本号为xmin）已经提交了的情况下，那么在xmin事务之后开始的新事务就都能够看到该元组，即xid&gt;&#x3D;xmin的事务均能看到该行（xid&#x3D;xmin则是一个事务未结束时再次scan表，能读取到之前插入的元组）；同理，xmax事务已提交的情况下，xid&gt;&#x3D;xmax的事务就读不到该行数据了。但若xmin未提交，那么即使xid&gt;&#x3D;xmin，事务xid也不能看见该行，xmax同理；<br>2.xmin或xmax&gt;xid，说明事务xmin(xmax)比当前事务晚创建，在可重复读隔离级别的事务中是不能看见的；但是如果是在隔离级别为读已提交的事务中，若对应该元组的插入或删除操作已经提交（xmin或xmax事务已提交），那么当前事务在第二遍scan表时则能读取到该元组的变化（提交插入，则第二遍扫描表时能看到该元组；提交删除，则该元组第二遍时不会被读取到）。<br>本实验中，快照读中，元组对一个事务是否可见的完整判断逻辑，如下图：</p><p><img src="https://img2.imgtp.com/2024/04/15/Ma807obu.png" alt="tup"><br>mvcc需要借助活跃事务集来判断一个元组的修改是否已提交。可重复读和读已提交获取的活跃事务集方法是不一样的。隔离级别为可重复读的事务因为看不到后续创建的新事务，所以它的活跃事务集应该是一个快照，包含在该事务创建时的所有活跃事务的集合，而隔离级别为读已提交的事务看到的活跃事务集则会随着新事务的开始和提交而更新。<br>快照读可以直接在tablescan中实现，但是若需要当前读，还需要在其他执行器中添加处理逻辑，同时对快照读实现中元组可见判断的一部分逻辑迁移到seqscan执行器中执行。</p><p>实现MV2PL<br>在mvcc中引入两阶段锁（two-phase-lock)。两阶段锁中，有粒度锁的概念，粒度有行级和表级。同时，有五种锁，分别为共享锁（Share)、排他锁(Exclusive)、意向共享锁（Intention Share Lock)、意向排他锁（Intention Exclusive Lock)、共享意向排他锁<br><img src="https://img2.imgtp.com/2024/04/15/kHmqShVq.png" alt="t"><br>意向锁是表级锁，只能对表上锁，意向共享锁代表的是要对该表的某些行进行读操作；意向排他锁代表要对该表的某些行进行写操作；共享锁和排他锁，两者均能对表和行上锁。<br>两阶段锁的实现<br>然后介绍下不同sql语句对应不同的加锁情况。<br>首先需要根据sql语句是否需要更新数据来判断。普通select语句，seqscan执行器只会对表加IS锁；<br>修改语句：<br>update：嵌套在update中的子seqscan执行器，其Ismodifedsql（）为true，即数据更新语句，需要加IX锁；<br>insert的子执行器不为seqscan执行器，所以直接在本执行器中对表上IX锁即可；<br>delete的子执行器同update一样，故在seqscan执行器中上IX锁；<br>本实验测试案例中的SIX锁：先对表设为share mode，也就是上S锁，再执行Insert操作加上IX锁，就变成了SIX锁。<br>当前读 Select for update 和 share的上锁：update是对行加写锁，share则是对行加读锁。<br>当前读不再是严格的snapshot Isolation，因为返回的是最新的数据<br><img src="https://img2.imgtp.com/2024/04/15/9mpnaEoV.png" alt="t"><br>锁维护使用的数据结构</p><p>维护每个表的锁请求队列，只要该锁请求的锁类型能兼容该队列中的任何锁请求的锁类型，则将该锁请求加入队列，如果该锁请求的锁类型不能兼容该队列中的任何一个，则返回false<br>锁升级的实现思路是，首先找到该事务xid想要上锁的表的锁请求队列，遍历一遍队列锁升级的类型是否与其他事务上的锁类型兼容，若兼容，再判断之前xid上过的锁能否直接升级，不能则再上新锁（锁类型为想要升级的类型）。<br>何为两阶段锁：第一阶段只能上锁不能解锁，第二阶段只能解锁不能上锁。<br>在事务提交后，才会将锁一次性释放，也就是强两阶段锁，保证了可串行化。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库lab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>huadb_lab2</title>
      <link href="/2024/04/15/huadb-lab2/"/>
      <url>/2024/04/15/huadb-lab2/</url>
      
        <content type="html"><![CDATA[<p>本实验的redo log和undo log均为物理日志，共用同一份日志文件，也就是redo&#x2F;undo log。undo log采用物理日志来回滚一个事务的实现为：在内存中维护一个活跃事务表，记录每一个活跃事务的最后一条操作的LSN位置，根据这个位置获取日志记录log_record，每个record_log都有该事务的上一条record_log的lsn，直到读取到事务的begin_log_record为止，就可以依次将一个事务的全部操作撤销。<br>在mysql中redo log是物理日志，而undo log是逻辑日志 </p><p>物理日志记录的是页面数据的更改<br>例如在本实验中，一条插入日志的内容如下：<br>事务id，对象id，当前页id，页内的slot id，改动数据所在页内偏移，记录的数据大小，记录的数据内容</p><p>在实验框架中，LSN 使用的是日志记录在日志文件中的位置表示，这种表示方法可以方便地通过 LSN 直接获取日志，无需再单独存一份 LSN 到日志位置的映射表。</p><p>首先说说幂等性：即同个操作无论做了多少遍，结果都是一样的，有f[f(x)] &#x3D; f(x)，为什么需要保证幂等性呢？<br>考虑一个问题：如果某个时间点发生故障，日志持久化了，但是实际操作有部分已经完成，但是有部分还没完成，那么进行故障恢复时扫描redo log重做了已经完成的部分，就会导致一个操作执行了多遍，比如在页内插入多条相同的数据。所以需要幂等性来保证无论重做多少遍，都不影响结果的正确性。<br>redolog为物理日志记录的是数据的变更位置，比如insert 操作实际执行的是把数据写到对应位置，那么只会重新在这个位置上再覆盖写一遍，而delete操作实际上是把对应的记录的删除flag标记为true（本实验的框架中），也只重新设置一遍，均不改变正确性。<br>log_record的redo函数只需使用日志来重新执行一遍操作，而物理日志方法来重做是能够保证幂等性的，因为日志记录了该元组位于页面的偏移量，只需在同个地方再插入一遍，所以如果原位置有数据，也只会进行覆盖。<br>另外，update的实现是由删除旧元组+插入新元组来实现的，所以update的日志即InsertLog和DeleteLog来实现。</p><p>事务的回滚：实验中Log_record包含有当前事务的上一条日志lsn，因此找到事务的最后一条lsn地址，即可遍历该事务的所有lsn。从后往前，对每个操作进行undo，插入操作是对数组做deleted标记为true，删除操作则deleted改为false，比较简单。</p><p>同时，在实验中可以发现物理日志的写入特点，如果有多个事务并发执行时，它们会交叉将日志记录写入缓冲区，不同于逻辑日志，逻辑日志只有在一个事务提交时才将完整记录进行一次写入，即逻辑日志的写入是按事务为单位的。</p><h2 id="ARIES恢复算法"><a href="#ARIES恢复算法" class="headerlink" title="ARIES恢复算法"></a>ARIES恢复算法</h2><p>首先要理解checkpoint，数据库在周期性将当前数据库的快照进行保存，以便数据库发生故障时进行恢复所需重做操作数量大大减少。<br>有两种实现，一种是停机保存，需要暂停服务，保证没有正在运行的事务，同时把所有脏页刷回磁盘。<br>实验采用的第二种，即不停机保存，实现方式是把当前活跃事务表和脏页表保存起来。那么在故障恢复时，与停机保存从checkpoint点开始重做不同，不停机保存需要从min(Rec LSNi)位置开始重做（即比较所有脏页的rec lsn，选出最小的lsn位置）<br><img src="https://img2.imgtp.com/2024/04/15/2QtgrRwj.png" alt="图片" title="结构图"><br>Dpt(Dirty page table):记录了每个脏数据页到第一条日志lsn（即RecLSN)的映射，每次记录日志时，均会判断该日志所改动的数据页是否存在于drity page table中，没有则添加，一旦进行flushpage后，首先把此页范围内的日志写到磁盘，同时会把该页从脏页表中移除。<br>ATT(active Transaction table):记录当前活跃事务到该活跃事务最后一条lsn的映射，用于撤销操作<br>Master Record记录的是begin checkpoint log 的lsn</p><p><img src="https://img2.imgtp.com/2024/04/15/LpQYIJaV.png" alt="图片" title="回滚过程"><br>ARIES 通过记录一条 Checkpoint Begin Log 来明确这个「某一时刻」的位置。<br> 详细步骤如下：</p><ol><li>先记录一条 Checkpoint Begin Log。</li><li>拷贝att和dpt</li><li>记录一条 Checkpoint End Log。Log 内容包括 ATT 和 DPT 的信息。然后把 Log 刷盘。</li><li>把 Checkpoint Begin Log 的 LSN 信息记录到 Master Record 中。</li></ol><p>Recovery 的时候，先从 Master Record 中找到 Checkpoint Begin Log 的位置，然后找到 Checkpoint End Log 的位置，恢复出 ATT 和 DPT 的初始状态<br><img src="https://img2.imgtp.com/2024/04/15/GouUPvl4.png" alt="Alt text" title="检查点"><br>本实验中，开始检查点日志和结束检查点日志连在一块，中间无其他事务日志。在redo中，应从所有脏页中最小的Rec lsn开始进行重做；undo则是需要在活跃事务表中找到事务的最后一条日志，然后依据该日志的prev_lsn找到前一条日志依次撤销操作。完成这些步骤后，数据库即可恢复原状。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库lab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客报告</title>
      <link href="/2024/04/15/blog-summry/"/>
      <url>/2024/04/15/blog-summry/</url>
      
        <content type="html"><![CDATA[<p>本人的博客是用Hexo生成的，下面来介绍下hexo和搭建过程。</p><p>Hexo是一个快速、简单且强大的静态博客框架，它使用Node.js为平台。以下是关于Hexo的简介：</p><h2 id="Hexo：静态博客框架"><a href="#Hexo：静态博客框架" class="headerlink" title="Hexo：静态博客框架"></a>Hexo：静态博客框架</h2><ul><li>快速: 使用最先进的技术，如Node.js，Hexo可以在几秒钟内从数百个文件生成静态网页。</li><li>简单: 一个简洁的命令行工具和易于配置的文件，使得使用Hexo开始写博客变得非常简单。只需一条命令就可以启动服务器，一条命令发布新文章。</li><li>Markdown 支持: 通过Markdown，您可以轻松写作。Hexo还支持GitHub Flavored Markdown、Octopress等的插件。</li><li>扩展性强: Hexo拥有强大的插件系统，你可以使用npm安装更多插件，满足各种需要。它也支持主题，允许用户轻松更改网站的外观和感觉。</li><li>一键部署: 内置一键部署功能，可以方便地将网站部署到GitHub Pages、Heroku或其他地方。</li></ul><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><p>学习Hexo之前，你需要了解以下技术或软件：</p><ul><li>Node.js: Hexo是基于Node.js构建的，因此你需要了解Node.js的基础知识。</li><li>npm (Node Package Manager): 用于安装和管理Node.js应用程序的依赖。</li><li>Git: 用于部署到GitHub Pages或其他Git托管服务。</li><li>Markdown: Hexo文章通常是用Markdown格式写的，因此了解基本的Markdown语法是很有帮助的。</li><li>基础的命令行操作: 由于Hexo的很多任务都是通过命令行完成的，所以了解基础的命令行操作会很有帮助。</li><li>JavaScript: 虽然不是必需的，但如果你想进行更高级的定制，了解JavaScript基础会很有帮助。<br>以上是学习Hexo之前应该了解的基础知识。一旦你熟悉了这些基础，使用和定制Hexo将会变得更加容易。</li></ul><h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><p>npm和nodejs的安装过程就不说了，只讲hexo的安装<br>使用npm安装Hexo： <code>npm install -g hexo-cli</code></p><h2 id="创建Hexo项目"><a href="#创建Hexo项目" class="headerlink" title="创建Hexo项目"></a>创建Hexo项目</h2><p>初始化一个新的Hexo项目：hexo init your-blog-name<br>进入项目目录：<code>cd your-blog-name</code></p><h2 id="部署到GitHub-Pages"><a href="#部署到GitHub-Pages" class="headerlink" title="部署到GitHub Pages"></a>部署到GitHub Pages</h2><p>要将 Hexo 博客部署到 GitHub Pages，你可以按照以下步骤操作：</p><h3 id="创建一个新的-GitHub-仓库"><a href="#创建一个新的-GitHub-仓库" class="headerlink" title="创建一个新的 GitHub 仓库:"></a>创建一个新的 GitHub 仓库:</h3><p>访问 GitHub 并登录。<br>点击右上角的 “+” 图标，然后选择 “New repository”。<br>为仓库命名。如果你希望你的博客地址为 username.github.io，则仓库名应为 username.github.io，其中 username 是你的 GitHub 用户名。<br>选择 “Public”，然后点击 “Create repository”。</p><h3 id="在-Hexo-博客的配置文件中设置部署配置"><a href="#在-Hexo-博客的配置文件中设置部署配置" class="headerlink" title="在 Hexo 博客的配置文件中设置部署配置:"></a>在 Hexo 博客的配置文件中设置部署配置:</h3><p>打开你的 Hexo 博客目录中的 _config.yml 文件。</p><p>在文件的底部，找到或添加 deploy 部分，并设置为以下内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy: yml</span><br><span class="line">  type: git</span><br><span class="line">  repo: https://github.com/username/username.github.io.git</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure><p>其中，username 是你的 GitHub 用户名。<br>安装 hexo-deployer-git: 在你的 Hexo 博客目录中，运行以下命令来安装部署插件：<br><code>npm install hexo-deployer-git --save</code></p><h3 id="部署你的博客"><a href="#部署你的博客" class="headerlink" title="部署你的博客:"></a>部署你的博客:</h3><p>在你的 Hexo 博客目录中，运行以下命令来部署你的博客到 GitHub Pages：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure><h3 id="访问你的博客"><a href="#访问你的博客" class="headerlink" title="访问你的博客:"></a>访问你的博客:</h3><p>一旦部署完成，你可以通过访问 <a href="https://username.github.io/">https://username.github.io</a> 来查看你的博客。（有时候，即使你推送了更改，GitHub Pages 也需要一些时间来构建和发布你的站点。这可能需要几分钟。稍后再次检查你的网站，看看是否可以访问。）</p><p>这些步骤应该能帮助你将 Hexo 博客部署到 GitHub Pages。</p><h2 id="主题定制："><a href="#主题定制：" class="headerlink" title="主题定制："></a>主题定制：</h2><p>Hexo 有一个活跃的社区，其中许多开发者制作并分享了大量的主题。<br>用户可以选择任何一个公开的 Hexo 主题并自由地进行定制。<br>主题通常包含一套模板、样式和功能。<br>_config.yml 文件中的 theme 配置项可以用来指定使用哪个主题。<br>定制主题通常涉及修改其模板文件、样式表或添加一些 JavaScript 功能。<br>我使用的是butterfly主题，比较热门,也是比较通用的模板。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>底层面经</title>
      <link href="/2024/04/14/mianjing/"/>
      <url>/2024/04/14/mianjing/</url>
      
        <content type="html"><![CDATA[<h2 id="LSM-Tree"><a href="#LSM-Tree" class="headerlink" title="LSM Tree"></a>LSM Tree</h2><h3 id="读写流程"><a href="#读写流程" class="headerlink" title="读写流程"></a>读写流程</h3><p>lsm-Tree适合写多读少的场景。日志结构合并树，它由三部分组成：memtable、immutable memtable和sstable。在内存，即memtable中维护以键排序的数据结构如跳表、b+树等，数据的插入、修改、删除首先在内存中进行，而且不像b+树，数据在原地修改，而是像日志一样以append方式，把数据的更新以记录形式append到内存（行的多个版本）。待写满后冻结memtable转为immutable memtable，变为只读，为了避免阻塞后续的更新，会创建一个新的memtable接替原来的memtable负责写，immutable memtable写入磁盘，形成sstable，每个immutable memtable对应一个sstable，全称为Sorted String table，它是位于磁盘上的一种持久化、有序且不可变的键值存储结构，它内部包含一系列可配置大小的Block（默认大小一般是64k）。Block的索引存储在尾部,当SSTable打开时，索引被加载到内存。然后根据key在导入内存里面再进行二分查找，找到key对应的offset之后，然后去磁盘把相应的数据块读出来。<br>这些SSTable文件，虽然每个文件中的key是有序的，但是文件之间完全完全无序造成还是无法查找。这里SSTable巧妙地采用了分层合并机制来解决乱序的问题。<br>查询时，从memtable-&gt; immutable memtable -&gt; sstable,在sstable倒着往前查询（最新的数据在最后），可以通过布隆过滤器、索引来优化查找速度。</p><h3 id="LSM造成的问题"><a href="#LSM造成的问题" class="headerlink" title="LSM造成的问题"></a>LSM造成的问题</h3><p>1）读放大，即读取的数据量比实际需要读取的数据量大。<br>2）写放大，写入的数据量比实际需要写入的数据量大。如compact操作。<br>3）空间放大，数据实际占用的磁盘空间比实际的大。即数据冗余。</p><h3 id="合并策略"><a href="#合并策略" class="headerlink" title="合并策略"></a>合并策略</h3><p>由于每个key的记录可能存在多份，合并时会消除冗余将数据合并成最新的一份。<br>trade-off</p><h4 id="Leveling策略"><a href="#Leveling策略" class="headerlink" title="Leveling策略"></a>Leveling策略</h4><h4 id="size-tiered-策略"><a href="#size-tiered-策略" class="headerlink" title="size-tiered 策略"></a>size-tiered 策略</h4><p>保证每一层的SSTable大小相近，同时限制每一层SSTable数量。待数量达N时进行合并写入下一层成为一个SSTable。<br>每一层中的SSTable文件之间可能有key重叠，所以读放大会很严重。<br>层数达到一定数量时，最底层的单个SSTable的大小会变得非常大。并且size-tiered策略会导致空间放大比较严重。</p><h3 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a>写时复制</h3><p>（Copy-on-write，简称COW）是一种优化策略。其核心思想是，如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是透明的。此作法主要的优点是如果调用者没有修改该资源，就不会有副本（private copy）被创建，因此多个调用者只是读取操作时可以共享同一份资源。</p><h3 id="为什么选用LSM"><a href="#为什么选用LSM" class="headerlink" title="为什么选用LSM?"></a>为什么选用LSM?</h3><p>一个是随机写顺序写的问题。一个是索引结构的并发插入修改有关。在LSM中维护索引结构采用的是跳表，不需要加latch，相比b+tree可以提高索引并发。<br>为什么有多个immutable table? 其实是内存与磁盘的鸿沟，内存写太快了，磁盘更新效率跟不上内存。<br>SSTable上使用稀疏索引来查找块，那么采用哪种稀疏索引？<br>采用B+Tree，而且由于数据是给定的，所以b+tree的空间利用率是100%.<br>由于这个过程容易出现非命中查询（即查询的数据不存在），可以引入布隆过滤器，如果没有命中则数据一定不在磁盘中。<br>WAL</p><h2 id="mysql分库分表、表分区"><a href="#mysql分库分表、表分区" class="headerlink" title="mysql分库分表、表分区"></a>mysql分库分表、表分区</h2><h3 id="表分区"><a href="#表分区" class="headerlink" title="表分区"></a>表分区</h3><p>表分区实际上是把一张表在物理结构上分为多个分区，磁盘上变为多个文件，即原本是一个表文件，现在拆分成了多个表文件，逻辑上还是同一张；<br>表分区只能水平划分，即以行为粒度进行划分<br>分区类型如下：</p><h4 id="RANGE"><a href="#RANGE" class="headerlink" title="RANGE"></a>RANGE</h4><p>按照一个字段范围进行分区，仅支持整数类型字段作为分区键，如果想要以日期字段来做数据分区，需要想将其转换为整数格式的时间戳。<br>例子<br>partition by range(r_id)(<br>partition p1 values less than (100000),<br>partition p2 values less than (200000),<br>partition p3 values less than (300000),<br>partition p4 values less than maxvalue<br>);<br>– 查询 zz_range 表中不同分区的数据量<br>select<br>    partition_name,table_rows<br>from<br>    information_schema.partitions<br>where<br>    table_name &#x3D; ‘zz_range’;</p><h4 id="LIST"><a href="#LIST" class="headerlink" title="LIST"></a>LIST</h4><p>枚举分区，只支持整数字段作为分区键。如果插入的数据在所有分区中找不到对应的值，会直接报错。<br>partition by list(l_sex)(<br>partition p1 values in (0),<br>partition p2 values in (1)<br>);</p><h4 id="KEY"><a href="#KEY" class="headerlink" title="KEY"></a>KEY</h4><p>在 hash 分区中，想要使用一个字段作为分区键，要么这个字段本身是整数类型，要么这个字段经过哈希函数处理后，能够得到一个整数的哈希值才行。但在 key 分区中，除开不支持 text、blob 两种类型外，其他类型的字段都可以作为分区键。<br>在 key 分区中也可以不显式指定分区键，MySQL 会自动选择，但不管是自己显式声明分区键，亦是 MySQL 自动选取分区键，都会遵循如下规则：</p><ul><li>表中只存在主键或唯一字段时，分区键必须为主键&#x2F;唯一键的部分或全部字段，不允许选择其他字段。</li><li>表中主键、唯一字段同时存在时，分区键必须为主键和唯一键共有的部分或全部字段。</li><li>当表中不存在主键或唯一键时，分区键可以是除 text、blob 类型外的任意单个或多个字段。<br>partition by key(k_name)partitions 3;</li></ul><h4 id="HASH"><a href="#HASH" class="headerlink" title="HASH"></a>HASH</h4><p>哈希分区中支持两种哈希分区法：</p><ul><li>常规哈希：基于某个整数型字段，直接做取模，最后根据余数来决定数据的分区。</li><li>线性哈希：基于某个字段哈希之后的哈希值，进行取模运算，最后根据余数来决定数据的分区。<br>常规哈希只能基于整数型字段对数据做划分；线性哈希则可以不限制字段的类型，只要能够通过 MySQL 哈希函数，转换出哈希值的字段类型都可以作为分区键（但本质上 MySQL 中好像没有提供将字符串转换为数值类型的哈希函数）。<br>– 选用 h_id 作为分区键，划分为三个分区<br>partition by hash(h_id)partitions 3;<br>– 使用线性哈希分区<br>partition by linear hash(lh_id)partitions 3;</li></ul><h4 id="SUB"><a href="#SUB" class="headerlink" title="SUB"></a>SUB</h4><p>又称子分区，所谓的子分区是指基于表分区后的结果，进一步做分区处理，也就是基于一个分区再做分区，好比一张表可以基于日期中的年份做分区，基于年份做了分区后，还可以基于年分区进一步做月分区。<br>这种方式要求每个一级分区下的二级分区数量都一致，同时二级分区的类型只能为 hash、key 类型。<br>partition by range(year(register_time))<br>subpartition by hash(month(register_time))<br>(<br>    partition p1 values less than (2000)(<br>        subpartition p1_s1,<br>        subpartition p1_s2<br>    ),<br>    partition p2 values less than (2020)(<br>        subpartition p2_s1,<br>        subpartition p2_s2),<br>    partition p3 values less than maxvalue(<br>    subpartition p3_s1,<br>    subpartition p3_s2<br>    )<br>);</p><h4 id="COLUMNS"><a href="#COLUMNS" class="headerlink" title="COLUMNS"></a>COLUMNS</h4><p>cloumns 分区实际上是 range、list 分区的变种，cloumns 分区可以使得 range、list 的分区键由多个字段来组成，同时支持的字段类型也相对更丰富一些，但这种分区法一般用的极少</p><h3 id="分表"><a href="#分表" class="headerlink" title="分表"></a>分表</h3><p>垂直分表<br>当一张表由于字段过多时，会导致表中每行数据的体积变大，一方面会导致磁盘 IO 次数增多，影响数据的读写效率；同时另一方面结果集响应时还会占用大量网络带宽，影响数据的传输效率；再从内存维度来看，单行数据越大，缓冲区中能放下的热点数据页会越少，当读写操作无法在内存中定位到相应的数据页，从而又会产生大量的磁盘 IO。<br>垂直分表可以根据冷热字段对表进行拆分。拆分的表中需要保存外键来建立联系。<br>由于修改数据时会同时修改多张表，所以需要使用事务来保证原子性。<br>水平分表<br>当一张表内的数据量过大（一般要求控制在 500-1200w 之间），查询性能就会下降，从而需要对表进行水平拆分。<br>水平分表后，多个表的表结构、索引相同，数据不同，每张表中会存储不同范围的数据。<br>水平分表和表分区十分类似，一般会选用水平分表方案。<br>由于数据会被存储到多个表中，所以进行增删改查数据前，需要定位到相应的表中再进行操作。且进行聚合操作时，需要从多个表中取出数据，再在后端进行聚合操作，或者依赖 Redis、ES 等第三方中间件来完成。<br>另外，可能出现多个表中 ID 相同，数据不同的情况，所以要合理设置 ID 规则来避免。比如可以设置交叉增长的 ID；可以利用特殊算法（雪花算法等）生成有序的分布式 ID；利用第三方中间件生成 ID 等。<br>###分库</p><h4 id="水平分库"><a href="#水平分库" class="headerlink" title="水平分库"></a>水平分库</h4><ul><li>水平分库和水平分表相似，并且关系紧密，水平分库就是将单个库中的表作水平分表，然后将子表分别置于不同的子库当中，独立部署。</li><li>因为库中内容的主要载体是表，所以水平分库和水平分表基本上如影随形。</li><li>例如用户表，我们可以使用注册时间的范围range来分表，将2020年注册的用户表usrtb2020部署在usrdata20中，2021年注册的用户表usrtb2021部署在usrdata21中。</li></ul><h4 id="垂直分库"><a href="#垂直分库" class="headerlink" title="垂直分库"></a>垂直分库</h4><p>特点，按业务归属</p><ul><li>同样的，垂直分库和垂直分表也十分类似，不过垂直分表拆分的是字段，而垂直分库，拆分的是表。</li><li>垂直分库是将一个库下的表作不同维度的分类，然后将其分配给不同子库的策略。</li><li>例如，我们可以将用户相关的表都放置在usrdata这个库中，将订单相关的表都放置在odrdata中，以此类推。</li><li>垂直分库的分类维度有很多，可以按照业务模块划分（用户&#x2F;订单…），按照技术模块分（日志类库&#x2F;图片类库…），或者空间，时间等等。</li></ul><h3 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a><a href="https://blog.csdn.net/weixin_43889788/article/details/128373848?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-128373848-blog-115289497.235%5Ev43%5Epc_blog_bottom_relevance_base9&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-128373848-blog-115289497.235%5Ev43%5Epc_blog_bottom_relevance_base9&utm_relevant_index=2">面试题</a></h3><h3 id="分表要停服嘛？不停服怎么做？"><a href="#分表要停服嘛？不停服怎么做？" class="headerlink" title="分表要停服嘛？不停服怎么做？"></a>分表要停服嘛？不停服怎么做？</h3><p>不用停服。不停服的时候，应该怎么做呢，主要分五个步骤：</p><p>编写代理层，加个开关（控制访问新的DAO还是老的DAO，或者是都访问），灰度期间，还是访问老的DAO。</p><p>发版全量后，开启双写，既在旧表新增和修改，也在新表新增和修改。日志或者临时表记下新表ID起始值，旧表中小于这个值的数据就是存量数据，这批数据就是要迁移的。</p><p>通过脚本把旧表的存量数据写入新表。</p><p>停读旧表改读新表，此时新表已经承载了所有读写业务，但是这时候不要立刻停写旧表，需要保持双写一段时间。</p><p>当读写新表一段时间之后，如果没有业务问题，就可以停写旧表啦</p><h3 id="分布式ID"><a href="#分布式ID" class="headerlink" title="分布式ID"></a>分布式ID</h3><p>主键生成机制。<br>数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID，或者使用雪花算法生成分布式ID。雪花算法是一种生成分布式全局唯一ID的算法，生成的ID称为Snowflake IDs。这种算法由Twitter创建，并用于推文的ID。<br>一个Snowflake ID有64位。</p><p>第1位：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。</p><p>接下来前41位是时间戳，表示了自选定的时期以来的毫秒数。</p><p>接下来的10位代表计算机ID，防止冲突。</p><p>其余12位代表每台机器上生成ID的序列号，这允许在同一毫秒内创建多个Snowflake ID。<br><img src="https://img2.imgtp.com/2024/04/15/JmurudAJ.png" alt="图片" title="ID"></p><h2 id="一致性哈希"><a href="#一致性哈希" class="headerlink" title="一致性哈希"></a>一致性哈希</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>场景：三台缓存服务器0，1，2号，用于缓存图片，现在有3万张图片需要缓存，我们希望这些图片被均匀的缓存到这3台服务器上，以便它们能够分摊缓存的压力。<br>第一种方法采用普通哈希，即hash（图片名称）% N，这里有三台服务器，故N&#x3D;3<br><img src="https://img2.imgtp.com/2024/04/15/w5s93wnQ.png" alt="图片" title="一致性哈希1"><br>虽然普通哈希能把数据均匀放到三台服务器上，但是如果服务器存满了，需要增加服务器节点，此时N变为4，那么之前存放的数据采用该哈希函数计算得到的地址也会产生变化，即5%3 &#x3D; 2    &#x3D;&gt;   5 % 4 &#x3D; 1，那么就需要将所有数据重新计算后搬迁到新的位置上，导致开销很大。<br>因此出现了一致性哈希方法</p><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol><li>一致性哈希的函数不再对服务器数量进行取模，而是hash(图片名称) % 2^32，即对2^32取模</li><li>一致性哈希将整个哈希值空间按照顺时针组成一个虚拟圆环：哈希环</li><li>对每台服务器，用该函数进行哈希，具体可以选择服务器的IP等关键字作为哈希函数的输入，确定在哈希环上的位置</li><li>使用该算法定位数据访问相应的服务器：将数据key使用hash计算出值，确定此数据在环上的位置，从此位置沿环顺时针，遇到的第一台服务器就是其定位的服务器，如下面的图，1 2数据对应服务器A,3对应B,4对应C<br><img src="https://img2.imgtp.com/2024/04/15/8aEZcZcW.png" alt="图片" title="一致性哈希2"></li></ol><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>前面提到的普通哈希函数，如果简单对服务器数量进行取模，那么服务器数量变化会导致缓存的雪崩，从而很有可能导致系统的崩溃。而一致性哈希算法就可以很好解决这个问题，因为当需要增加或减少服务器时，只会使得哈希环上的一部分数据缓存失效，不至于将所有压力都同时间集中到后端服务器上<br>可扩展哈希的扩展过程也很相似，每次扩容后，只需把溢出的桶中所有元素进行重映射<br> hash 环的倾斜在极端情况下，仍然有可能引起系统的崩溃，为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点，一个实际物理节点可以对应多个虚拟节点，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大，hash环倾斜所带来的影响就越小，同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射。具体做法可以在服务器ip或主机名的后面增加编号来实现，加入虚拟节点以后的hash环如下：<br><img src="https://img2.imgtp.com/2024/04/15/Dkl5Hr27.png" alt="图片" title="一致性哈希3"></p><h2 id="c"><a href="#c" class="headerlink" title="c++"></a>c++</h2><p>###智能指针<br>智能指针是一个类，这个类的构造函数中传入一个普通指针，析构函数中释放传入的指针。智能指针的类都是栈上的对象，所以当函数（或程序）结束时会自动被释放，</p><ol><li>shared_ptr<br>基于引用计数的智能指针。可随意赋值，直到内存的引用计数为0的时候这个内存会被释放。</li><li>weak_ptr<br>引用计数有个问题就是如果两个指针互相引用形成环，那么两个指针指向的内存均无法释放。弱指针是用于引用共享指针使用的。共享指针每次被引用都会计数+1，但是弱指针只引用不计数，也就是说共享指针如果进行析构了，那么即使有弱指针引用，也会将内存释放；所以弱指针使用的时候，还需要注意判断指针是否非空。</li><li>unique_ptr<br>不支持赋值和拷贝，会报错。只能通过std::move()来转移指针。</li></ol><h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><ol><li>static_cast用于在类型之间进行转换，它是编译时强制转换。</li><li>const_cast主要用于去除指针或引用类型的const属性。此操作可能会导致未定义的行为，所以需要慎用。</li><li>dynamic_cast主要用于运行时的从父类指针向子类指针转换，如果转换不成功则返回nullptr。</li><li>reinterpret_cast可以将指针或引用转换为任何类型的指针或引用。reinterpret_cast实现依赖于编译器和硬件，可能导致未定义的行为。</li><li>为什么还引入这些类型转换？<br>主要有三点，更安全、更灵活、可读性更好。</li><li>什么是隐式转换？<br>隐式转换是指在表达式中自动进行的类型转换。比如int 和 double相加，会把int先转为double，然后再进行求和。如果不想让其尝试隐式转换，可以在编译选项添加-Werror&#x3D;conversion。或者explicit关键字来让变量禁止隐式转换。</li></ol><h3 id="move-和forward"><a href="#move-和forward" class="headerlink" title="move()和forward()"></a>move()和forward()</h3><p>move和forward的内部实现本质上都调用了static_cast，它们的使用场景不同。前者会将任何一个变量无条件地转化成右值，用于move语义；而后者则会有条件地（当且仅当该变量是右值，如果输入的变量是左值，那么forward将输入的变量转化成左值）将变量转化成右值，通常用于在模版函数中转发和保留原始变量的左值和右值属性。</p><h2 id="B-tree"><a href="#B-tree" class="headerlink" title="B+tree"></a>B+tree</h2><h3 id="二级索引的value应该选主键还是数据所在块的指针？"><a href="#二级索引的value应该选主键还是数据所在块的指针？" class="headerlink" title="二级索引的value应该选主键还是数据所在块的指针？"></a>二级索引的value应该选主键还是数据所在块的指针？</h3><p>如果选择数据所在块的指针，虽然寻址会很方便，但是如果B+tree进行了分裂和删除，所在块已经不是原来数据存放的地址了，就会失效；而且选择主键的话虽然要进行搜寻，但是由于大部分内部节点都在缓存，所以其实很多情况下只需要在内存中遍历，开销很小。</p><h3 id="B-树的缺点，随机读写为什么比顺序读写慢"><a href="#B-树的缺点，随机读写为什么比顺序读写慢" class="headerlink" title="B+树的缺点，随机读写为什么比顺序读写慢?"></a>B+树的缺点，随机读写为什么比顺序读写慢?</h3><p>跟磁盘结构有关，SSD的流行，SSD的随机写性能很差。随机写会导致多个页面发生变动，需要时常进行磁盘碎片的整理，这个过程得把磁盘中的页读到内存中，增加了IO次数。随机读的话会频繁移动磁臂，移动磁臂所花费的时间是ms级别的。<br>顺序io则不会导致上述问题</p><h2 id="LRU-缓冲池"><a href="#LRU-缓冲池" class="headerlink" title="LRU,缓冲池"></a>LRU,缓冲池</h2><p>15445的LRU算法，在链表中的页在换出的时候，需要将页写入磁盘。那么要等待页写入磁盘后再继续读写吗？怎么做优化？<br>其实可以换出时将脏页使用链表存储连接。steal机制<br>如何进行刷脏：检查点进程控制WAL和缓冲池，确保两者协同工作。只有在缓冲池中的数据页完成落盘后相关的操作日志记录才能从WAL中丢弃。<br>如何进行200Gcache的刷脏？<br>脏页按照日志的LSN来排序，如果一个脏页被写了多次，那么它应该用哪一次的LSN来排序？<br>跟它的故障恢复有关，其实需要按第一次LSN，在进行redo的时候，都是需要顺序按LSN来重做的。<br>如果checkpoint5~10分钟做一次刷脏，磁盘承受不住，该怎么做？<br>做增量检查点，保证平缓地进行磁盘刷数据。</p><h2 id="进程通信的方法"><a href="#进程通信的方法" class="headerlink" title="进程通信的方法"></a>进程通信的方法</h2><p>1.socket和RPC有什么关系<br>以模块调用的简单性忽略通讯的具体细节。RPC实际上底层就是由socket实现的，RPC的出现实际上是希望程序之间的通信只需要通过简单的模块功能的调用来进行网络通信，让操作就像是在同一台机器同个程序一样。</p><h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><h3 id="传统隔离级别"><a href="#传统隔离级别" class="headerlink" title="传统隔离级别"></a>传统隔离级别</h3><p>其实是用于2PL而定义的。RU，会产生读脏、不可重复读、幻读。RC则不会读脏，RR不会读脏、可重复读。<br>可串行化则全部解决。读脏是指读到其他事务未提交的数据，其实是因为RU在实现时读行不加锁，修改才加锁，如果对同个行进行访问，那么其他事务就算加了锁，依旧能够读该行，导致出现读脏；不可重复读就更容易解释了，因为修改后第二次读取发现数据不一致，幻读则是由于行的插入和删除导致事务执行相同的select读取到的结果集不一样；然后是读已提交，它多加了读锁的实现，两阶段锁第一阶段只加锁，第二阶段释放锁，但是读已提交能够在收缩阶段加读锁；那么就意味着待其他事务提交后，再次读同个行会出现不一致的数据，这就是不可重复读。<br>可重复读，则在收缩阶段只能释放锁，保证了不会出现上述情况，但是依旧不能解决插入操作导致的幻读，需要多加一个index lock的实现才能解决，gap lock，也就是实现可串行化。<br><img src="https://img2.imgtp.com/2024/04/15/2ykPxJQc.png" alt="图片" title="2pl读已提交的实现"></p><h3 id="快照隔离级别"><a href="#快照隔离级别" class="headerlink" title="快照隔离级别"></a>快照隔离级别</h3><p>快照隔离，多版本并发控制能够解决写写冲突的问题。这里面讲到的快照隔离级别，能解决读已提交，可重复读，和幻读的问题，但是会引入新的问题write-skew，即两个事务互相修改对方读取的数据形成了依赖环，也就是读写冲突，为了保证可串行化，可以将读-写冲突转成写-写冲突，那快照隔离的验证机制就能检测到读-写冲突了。所以有的数据库系统会提供机制（例如 for update 语句）让程序员将读操作标记为写操作，对于需要保证从串行化的读写事务，可以用这种机制让并发事务的读-写冲突变成写-写冲突，从而被事务隔离的验证机制检测到。</p><ul><li>write skew 说到底是一种读-写冲突，并发事务修改了彼此依赖的不同数据项。而快照隔离的验证机制只能检测到写-写冲突，读写冲突被掩盖，导致并发执行的结果不能串行化。如果将读-写冲突转成写-写冲突，那快照隔离的验证机制就能检测到读-写冲突了。所以有的数据库系统会提供机制（例如 for update 语句）让程序员将读操作标记为写操作，对于需要保证从串行化的读写事务，可以用这种机制让并发事务的读-写冲突变成写-写冲突，从而被事务隔离的验证机制检测到。</li></ul><p><a href="https://techcommunity.microsoft.com/t5/sql-server-blog/serializable-vs-snapshot-isolation-level/ba-p/383281">sql-server的快照隔离</a></p>]]></content>
      
      
      <categories>
          
          <category> 底层面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 底层面经 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>leetcode</title>
      <link href="/2024/04/13/leetcode/"/>
      <url>/2024/04/13/leetcode/</url>
      
        <content type="html"><![CDATA[<h2 id="移除数组的重复元素"><a href="#移除数组的重复元素" class="headerlink" title="移除数组的重复元素"></a>移除数组的重复元素</h2><p>首先处理特殊情况：如果数组长度为0，直接返回；<br>因此从下标1开始处理数组，由于给定的数组 nums 是有序的，对于i &lt;&#x3D; k &lt;&#x3D; j ，有nums[i]&#x3D;nums[k]&#x3D;nums[j]<br>设置快慢指针slow ,fast, 均从1开始，nums[0~slow-1]是不重复的被保留数组元素<br>若nums[fast] !&#x3D; nums[slow - 1]，则说明当前元素与被保留数组的元素都不一样，可以纳入被保留数组直接让nums[slow] &#x3D; nums[fast]</p><h2 id="移除数组的重复元素2"><a href="#移除数组的重复元素2" class="headerlink" title="移除数组的重复元素2"></a>移除数组的重复元素2</h2><p>处理特殊情况：如果数组长度&lt; 2，直接返回；<br>从下标2开始处理数组，快慢指针slow,fast均为2,nums[0~slow-1]是能够被保留的数组元素<br>若nums[fast] !&#x3D; nums[slow - 2]，也就是说如果当前元素与被保留的元素中倒数第二个元素不一样，那么说明该元素与被保留数组的最后两位元素都不一样，可以纳入被保留数组，即让nums[slow] &#x3D; nums[right]，slow++ </p><h2 id="多数元素"><a href="#多数元素" class="headerlink" title="多数元素"></a>多数元素</h2><p>给定一个大小为 n 的数组 nums ，返回其中的多数元素。多数元素是指在数组中出现次数 大于 ⌊ n&#x2F;2 ⌋ 的元素。<br>以O(N)的时间复杂度，O(1)的空间复杂度解决。<br>这是我目前看到的最直观形象的解法，时间复杂度O(n)，空间复杂度O(1)。<br>“同归于尽消杀法” ：<br>由于多数超过50%, 比如100个数，那么多数至少51个，剩下少数是49个。<br> a. 第一个到来的士兵，直接插上自己阵营的旗帜占领这块高地，此时领主 winner 就是这个阵营的人，现存兵力 count &#x3D; 1。<br> b. 如果新来的士兵和前一个士兵是同一阵营，则集合起来占领高地，领主不变，winner 依然是当前这个士兵所属阵营，现存兵力 count++；<br> c. 如果新来到的士兵不是同一阵营，则前方阵营派一个士兵和它同归于尽。 此时前方阵营兵力count –。（即使双方都死光，这块高地的旗帜 winner 依然不变，因为已经没有活着的士兵可以去换上自己的新旗帜）<br> d. 当下一个士兵到来，发现前方阵营已经没有兵力，新士兵就成了领主，winner 变成这个士兵所属阵营的旗帜，现存兵力 count ++。<br>就这样各路军阀一直以这种以一敌一同归于尽的方式厮杀下去，直到少数阵营都死光，那么最后剩下的几个必然属于多数阵营，winner 就是多数阵营。（多数阵营 51个，少数阵营只有49个，死剩下的2个就是多数阵营的人）</p><h2 id="字母异位词分组"><a href="#字母异位词分组" class="headerlink" title="字母异位词分组"></a>字母异位词分组</h2><p>给你一个字符串数组，请你将 字母异位词 组合在一起。可以按任意顺序返回结果列表。字母异位词 是由重新排列源单词的所有字母得到的一个新单词。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">示例 </span><br><span class="line">输入: strs = [&quot;eat&quot;, &quot;tea&quot;, &quot;tan&quot;, &quot;ate&quot;, &quot;nat&quot;, &quot;bat&quot;]</span><br><span class="line">输出: [[&quot;bat&quot;],[&quot;nat&quot;,&quot;tan&quot;],[&quot;ate&quot;,&quot;eat&quot;,&quot;tea&quot;]]</span><br></pre></td></tr></table></figure><h3 id="字符串排序方法"><a href="#字符串排序方法" class="headerlink" title="字符串排序方法"></a>字符串排序方法</h3><p>把所有字符串都按字母表进行排序，含有相同字母的字符串都会变成一样的顺序，如eat -&gt; aet , tea -&gt; aet ，再创建从字符串映射到字符串容器的哈希表，遍历字符串数组，把相同字符串映射到同一个容器中。 时间复杂度O(nklogk) ，空间复杂度O(n)</p><h3 id="字符串计数器方法"><a href="#字符串计数器方法" class="headerlink" title="字符串计数器方法"></a>字符串计数器方法</h3><p> a. 使用哈希表。键为计数排序字符串key，这个技术排序字符串key的意思是按照字母顺序表排序，同时每个字母会注明出现次数，比如”cat” “atc” 对应的字符串为 “a1c1t1”；值为字符串数组。<br> b. 遍历输入的字符串数组中的每一个字符串，转换为key，然后放到哈希表对应的位置。<br> c. 最后把哈希表的所有值即字符串数组放到结果返回。<br>时间复杂度为O(nk)，每个字符串都需要转化为计数排序字符串。<br>空间复杂度为O(n),需要使用哈希表存储</p><h2 id="接雨水"><a href="#接雨水" class="headerlink" title="接雨水"></a>接雨水</h2><p>给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。<br><img src="https://img2.imgtp.com/2024/04/15/l9Oyoxky.png" alt="图片" title="接雨水"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">输入：height = [0,1,0,2,1,0,1,3,2,1,2,1]</span><br><span class="line">输出：6</span><br><span class="line">解释：上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）。 </span><br><span class="line">示例 2：</span><br><span class="line">输入：height = [4,2,0,3,2,5]</span><br><span class="line">输出：9</span><br></pre></td></tr></table></figure><h3 id="1-动态规划"><a href="#1-动态规划" class="headerlink" title="1.动态规划"></a>1.动态规划</h3><p>维护两个数组，leftmax[n], rightmax[n]，leftmax数组每个元素代表的是左边到该下标为止最高的高度，rightmax数组每个元素则是右边最高的高度。<br>设置一个sum变量用来计数总雨水量，遍历height数组，每个元素能容纳的雨水单位为min (leftmax[i], rightmax[i]) - height[i]<br>时间复杂度为O(n),空间复杂度为O(n)</p><h3 id="2-双指针"><a href="#2-双指针" class="headerlink" title="2.双指针"></a>2.双指针</h3><p>动态规划需要O(n)空间复杂度，设置一个雨水总容纳量sum,设置left和right指针分别从最左和最右边开始，设置leftMax和rightMax分别代表左边的最高值和右边的最高值；left往右，right往左，直到相遇时停止。<br>类似于两队人打擂台赛（没有体力消耗），永远都是最强的留在场上（继续守擂）<br>直到有另一个更强的击败他成为全场最强（全场最强同时也是他所在队伍目前出场的最强）<br>举例，有A队和B队<br>B队攻擂成功-&gt;B队当前攻擂人比A队所有人都厉害<br>curB &gt; curA -&gt; curB &gt; Max(A) -&gt; MAX(B) &gt; Max(A)<br>A队守擂成功-&gt;A队当前守擂人比B队所有人都厉害<br>curA &gt; curB -&gt; curA &gt; Max(B) -&gt; Max(A) &gt; MAX(B)<br>也就是说，如果当前左边的高度小于右边的高度，说明右边依旧是当前最高的，可以计算左边格子容纳的水量，不用担心左指针的右边太矮，因为最终右边会由右指针的最高或者左指针的最高来支撑</p><h2 id="找到字符串中所有字母异位词"><a href="#找到字符串中所有字母异位词" class="headerlink" title="找到字符串中所有字母异位词"></a>找到字符串中所有字母异位词</h2><p>给定两个字符串 s 和 p，找到 s 中所有 p 的 异位词 的子串，返回这些子串的起始索引。不考虑答案输出的顺序。<br>异位词 指由相同字母重排列形成的字符串（包括相同的字符串）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入: s = &quot;cbaebabacd&quot;, p = &quot;abc&quot;</span><br><span class="line">输出: [0,6]</span><br></pre></td></tr></table></figure><p>解释:<br>起始索引等于 0 的子串是 “cba”, 它是 “abc” 的异位词。<br>起始索引等于 6 的子串是 “bac”, 它是 “abc” 的异位词。<br>设置一个count数组记录p中所有字母的个数，用left、right指针来维护一个窗口的左右边界，然后遍历s。<br>先将字母c放入窗口，对应的count[c]减1，然后进行判断窗口中是否有多余的字母，这个多余的判断使用count[c]是否小于0，小于0说明目前装入的字母不是我们需要的字母或者已经超过异味词所需字母数量，从left指针处开始拿出字母，直到满足count[c]不小于0；在每一轮的最后判断当前窗口大小是否等于异位词长度，是则将left指针放入结果集。<br>空间复杂度O(k),时间复杂度O(n)</p>]]></content>
      
      
      <categories>
          
          <category> 力扣刷题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 力扣专题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>这是smog1995的个人博客</title>
      <link href="/2024/04/08/hello-world/"/>
      <url>/2024/04/08/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> 个人介绍 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人介绍 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
